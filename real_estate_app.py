# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from io import BytesIO
from sklearn.ensemble import RandomForestRegressor
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder

# Set page configuration
st.set_page_config(
    page_title="Real Estate Analysis",
    page_icon="üìä",
    layout="wide"
)

# Configure matplotlib with a simple style
plt.rcParams.update({
    'figure.figsize': [10, 6],
    'axes.grid': True,
    'grid.alpha': 0.3,
    'axes.labelsize': 12,
    'axes.titlesize': 14
})

# === Column Templates ===
STANDARD_COLUMNS = {
    "–ö–æ–º–ø–ª–µ–∫—Å": ["–ö–æ–º–ø–ª–µ–∫—Å", "Project", "Name"],
    "–†–∞–π–æ–Ω": ["–†–∞–π–æ–Ω", "District", "Area"],
    "–ü–ª–æ—â–∞–¥—å": ["–ü–ª–æ—â–∞–¥—å", "–ü–ª–æ—â–∞–¥—å (–º¬≤)", "Area (sqm)"],
    "–°–ø–∞–ª–µ–Ω": ["–°–ø–∞–ª–µ–Ω", "Bedrooms"],
    "–≠—Ç–∞–∂–µ–π": ["–≠—Ç–∞–∂–µ–π", "Floors"],
    "–¶–µ–Ω–∞_‡∏ø": ["Price, ‡∏ø", "–¶–µ–Ω–∞", "Price (THB)"]
}

st.title("üì• –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑ Excel-—Ñ–∞–π–ª–æ–≤ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏")

def read_file_safely(file, is_csv=True, header_row=0):
    try:
        if is_csv:
            # Try different encodings
            encodings = ['utf-8', 'cp1251', 'latin1']
            for encoding in encodings:
                try:
                    return pd.read_csv(file, header=header_row, encoding=encoding)
                except UnicodeDecodeError:
                    continue
            raise ValueError("Could not read the file with any supported encoding")
        else:
            return pd.read_excel(file, header=header_row)
    except Exception as e:
        st.error(f"Error reading file: {str(e)}")
        return None

uploaded_files = st.file_uploader(
    "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ Excel-—Ñ–∞–π–ª–æ–≤", 
    type=["xlsx", "xls", "csv"], 
    accept_multiple_files=True
)

if uploaded_files:
    all_data = []
    
    for file in uploaded_files:
        st.subheader(f"üìÑ –§–∞–π–ª: {file.name}")
        
        try:
            is_csv = file.name.endswith('.csv')
            
            # Preview the file
            if is_csv:
                df_preview = read_file_safely(file, is_csv=True, header_row=None)
            else:
                df_preview = read_file_safely(file, is_csv=False, header_row=None)
            
            if df_preview is None:
                st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª {file.name}")
                continue
                
            st.write("üßæ –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä:", df_preview.head())
            
            # Get header row from user
            header_row = st.number_input(
                f"üß© –í –∫–∞–∫–æ–π —Å—Ç—Ä–æ–∫–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –≤ {file.name}?",
                min_value=0,
                max_value=10,
                value=0 if is_csv else 1,
                key=f"header_{file.name}"
            )
            
            # Read the full file with the specified header
            df = read_file_safely(file, is_csv=is_csv, header_row=header_row)
            
            if df is None or df.empty:
                st.warning(f"–§–∞–π–ª {file.name} –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã—Ö")
                continue
            
            st.write("üîé –ù–∞–π–¥–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏:", list(df.columns))

            # Column mapping
            column_map = {}
            for std_col, aliases in STANDARD_COLUMNS.items():
                match = next((alias for alias in aliases if alias in df.columns), None)
                column_map[std_col] = st.selectbox(
                    f"üß© –°–æ–ø–æ—Å—Ç–∞–≤—å—Ç–µ –∫–æ–ª–æ–Ω–∫—É –¥–ª—è '{std_col}'",
                    options=[""] + list(df.columns),
                    index=(list(df.columns).index(match) + 1) if match else 0,
                    key=f"{file.name}_{std_col}"
                )

            # Create mapped dataframe
            mapped_df = pd.DataFrame()
            for std_col, selected_col in column_map.items():
                if selected_col:
                    mapped_df[std_col] = df[selected_col]
                else:
                    mapped_df[std_col] = None

            all_data.append(mapped_df)
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file.name}: {str(e)}")
            continue

    if not all_data:
        st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∏ –æ–¥–∏–Ω —Ñ–∞–π–ª")
        st.stop()

    try:
        # Combine all files
        result_df = pd.concat(all_data, ignore_index=True)
        if result_df.empty:
            st.warning("–ü–æ—Å–ª–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ –¥–∞–Ω–Ω—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")
            st.stop()
            
        st.success("‚úÖ –§–∞–π–ª—ã —É—Å–ø–µ—à–Ω–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã!")
        st.dataframe(result_df)

        # === Price calculations ===
        try:
            result_df['–¶–µ–Ω–∞_‡∏ø'] = pd.to_numeric(
                result_df['–¶–µ–Ω–∞_‡∏ø'].astype(str).str.replace(' ', '').str.replace(',', ''),
                errors='coerce'
            )
            result_df['–ü–ª–æ—â–∞–¥—å'] = pd.to_numeric(result_df['–ü–ª–æ—â–∞–¥—å'], errors='coerce')
            result_df['–¶–µ–Ω–∞_–∑–∞_–º2'] = result_df['–¶–µ–Ω–∞_‡∏ø'] / result_df['–ü–ª–æ—â–∞–¥—å']
        except Exception as e:
            st.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ —Ü–µ–Ω—ã –∑–∞ –º¬≤: {str(e)}")

        # === üí° –ê–Ω–∞–ª–∏–∑ –≤—ã–≥–æ–¥–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ ===
        st.header("üí° –í—ã–≥–æ–¥–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã (—Ü–µ–Ω–∞ –∑–∞ –º¬≤ < 80% –æ—Ç —Å—Ä–µ–¥–Ω–µ–π –ø–æ —Ä–∞–π–æ–Ω—É)")
        if '–†–∞–π–æ–Ω' in result_df.columns and '–¶–µ–Ω–∞_–∑–∞_–º2' in result_df.columns:
            avg_by_area = result_df.groupby('–†–∞–π–æ–Ω')['–¶–µ–Ω–∞_–∑–∞_–º2'].mean()
            result_df['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_–æ—Ç_—Å—Ä–µ–¥–Ω–µ–π'] = result_df.apply(
                lambda row: row['–¶–µ–Ω–∞_–∑–∞_–º2'] / avg_by_area[row['–†–∞–π–æ–Ω']]
                if pd.notnull(row['–†–∞–π–æ–Ω']) and row['–†–∞–π–æ–Ω'] in avg_by_area else None,
                axis=1
            )
            profitable_df = result_df[result_df['–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ_–æ—Ç_—Å—Ä–µ–¥–Ω–µ–π'] < 0.8]
            st.dataframe(profitable_df)

        # === üìà –ì—Ä–∞—Ñ–∏–∫ —Å—Ä–µ–¥–Ω–µ–π —Ü–µ–Ω—ã –ø–æ —Ä–∞–π–æ–Ω–∞–º ===
        st.header("üìà –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ –∑–∞ –º¬≤ –ø–æ —Ä–∞–π–æ–Ω–∞–º")
        if '–†–∞–π–æ–Ω' in result_df.columns and '–¶–µ–Ω–∞_–∑–∞_–º2' in result_df.columns:
            avg_price_chart = result_df.groupby('–†–∞–π–æ–Ω')['–¶–µ–Ω–∞_–∑–∞_–º2'].mean().sort_values()
            fig, ax = plt.subplots(figsize=(10, 5))
            avg_price_chart.plot(kind='barh', ax=ax)
            ax.set_xlabel("–¶–µ–Ω–∞ –∑–∞ –º¬≤ (‡∏ø)")
            ax.set_title("–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ –∑–∞ –º¬≤ –ø–æ —Ä–∞–π–æ–Ω–∞–º")
            st.pyplot(fig)

        # === ü§ñ AI-–ø—Ä–æ–≥–Ω–æ–∑ —Ü–µ–Ω—ã ===
        st.header("ü§ñ –ü—Ä–æ–≥–Ω–æ–∑ —Ü–µ–Ω—ã –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º")
        model_data = result_df.dropna(subset=['–ü–ª–æ—â–∞–¥—å', '–°–ø–∞–ª–µ–Ω', '–≠—Ç–∞–∂–µ–π', '–†–∞–π–æ–Ω', '–¶–µ–Ω–∞_‡∏ø'])

        if not model_data.empty:
            X = model_data[['–ü–ª–æ—â–∞–¥—å', '–°–ø–∞–ª–µ–Ω', '–≠—Ç–∞–∂–µ–π', '–†–∞–π–æ–Ω']]
            y = model_data['–¶–µ–Ω–∞_‡∏ø']

            preprocessor = ColumnTransformer([
                ('cat', OneHotEncoder(handle_unknown='ignore'), ['–†–∞–π–æ–Ω'])
            ], remainder='passthrough')

            model = Pipeline([
                ('prep', preprocessor),
                ('rf', RandomForestRegressor(random_state=42))
            ])

            model.fit(X, y)

            col1, col2 = st.columns(2)
            with col1:
                input_area = st.number_input("–ü–ª–æ—â–∞–¥—å (–º¬≤)", min_value=20, max_value=1000, value=150)
                input_bedrooms = st.number_input("–°–ø–∞–ª–µ–Ω", min_value=1, max_value=10, value=3)
            with col2:
                input_floors = st.number_input("–≠—Ç–∞–∂–µ–π", min_value=1, max_value=5, value=1)
                input_district = st.selectbox("–†–∞–π–æ–Ω", sorted(model_data['–†–∞–π–æ–Ω'].dropna().unique()))

            input_df = pd.DataFrame([{
                '–ü–ª–æ—â–∞–¥—å': input_area,
                '–°–ø–∞–ª–µ–Ω': input_bedrooms,
                '–≠—Ç–∞–∂–µ–π': input_floors,
                '–†–∞–π–æ–Ω': input_district
            }])

            predicted_price = model.predict(input_df)[0]
            st.subheader(f"üí∞ –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º–∞—è —Ü–µ–Ω–∞: **‡∏ø {int(predicted_price):,}**")
        else:
            st.warning("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è.")

        # Export to Excel
        try:
            output = BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                result_df.to_excel(writer, index=False, sheet_name='Combined Data')
            output.seek(0)

            st.download_button(
                label="üíæ –°–∫–∞—á–∞—Ç—å –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π —Ñ–∞–π–ª –≤ Excel",
                data=output,
                file_name="combined_real_estate.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ Excel —Ñ–∞–π–ª–∞: {str(e)}")
            
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–æ–≤: {str(e)}")
