import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from io import BytesIO

# –®–∞–±–ª–æ–Ω —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
STANDARD_COLUMNS = {
    "–ö–æ–º–ø–ª–µ–∫—Å": ["–ö–æ–º–ø–ª–µ–∫—Å", "Project", "Name", "SALES"],
    "–†–∞–π–æ–Ω": ["–†–∞–π–æ–Ω", "District", "Area", "Location"],
    "–ü–ª–æ—â–∞–¥—å": ["–ü–ª–æ—â–∞–¥—å", "–ü–ª–æ—â–∞–¥—å (–º¬≤)", "Area (sqm)", "Area", "SQM"],
    "–°–ø–∞–ª–µ–Ω": ["–°–ø–∞–ª–µ–Ω", "Bedrooms", "Beds", "Bed"],
    "–≠—Ç–∞–∂–µ–π": ["–≠—Ç–∞–∂–µ–π", "Floors", "Floor"],
    "–¶–µ–Ω–∞": ["Price, ‡∏ø", "–¶–µ–Ω–∞", "Price (THB)", "Price", "THB"]
}

def detect_header_row(df, max_rows_to_check=5):
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—É—é —Å—Ç—Ä–æ–∫—É –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤"""
    preview_rows = []
    best_header_score = 0
    suggested_header_row = 0

    for i in range(min(max_rows_to_check, len(df))):
        row = df.iloc[i]
        non_empty = row.count()
        unnamed_count = sum(1 for col in row.index if 'Unnamed' in str(col))
        
        # Calculate header likelihood score
        score = 0
        row_values = [str(val).strip() for val in row if pd.notna(val)]
        
        # Characteristics of a header row:
        # 1. High number of non-empty cells
        score += non_empty * 2
        
        # 2. Low number of numeric values (headers are usually text)
        numeric_count = sum(1 for val in row_values if str(val).replace('.', '').isdigit())
        score -= numeric_count * 3
        
        # 3. No very long text (headers are usually short)
        long_text_count = sum(1 for val in row_values if len(str(val)) > 50)
        score -= long_text_count * 2
        
        # 4. Common header keywords
        header_keywords = ['project', 'type', 'size', 'area', 'price', 'location', 'floor', 'room', 'bed', 'bath', 'contact']
        keyword_matches = sum(1 for val in row_values if any(keyword.lower() in str(val).lower() for keyword in header_keywords))
        score += keyword_matches * 3
        
        # 5. Penalize rows with URLs or contact information
        url_count = sum(1 for val in row_values if 'http' in str(val).lower() or 'www' in str(val).lower())
        phone_count = sum(1 for val in row_values if any(char.isdigit() for char in str(val)) and '+' in str(val))
        score -= (url_count + phone_count) * 5
        
        # Store row information
        row_info = {
            'row_num': i,
            'content': row.tolist(),
            'non_empty': non_empty,
            'unnamed_count': unnamed_count,
            'score': score,
            'header_likelihood': '–ù–∏–∑–∫–∞—è'
        }
        
        # Update best score
        if score > best_header_score:
            best_header_score = score
            suggested_header_row = i
            
        preview_rows.append(row_info)
    
    # Update likelihood labels
    for row in preview_rows:
        if row['row_num'] == suggested_header_row:
            row['header_likelihood'] = '–í—ã—Å–æ–∫–∞—è'
        elif row['score'] > best_header_score * 0.7:
            row['header_likelihood'] = '–°—Ä–µ–¥–Ω—è—è'
    
    return preview_rows, suggested_header_row

def analyze_prices(df):
    """–ê–Ω–∞–ª–∏–∑ —Ü–µ–Ω –ø–æ —Ä–∞–π–æ–Ω–∞–º"""
    if '–¶–µ–Ω–∞' not in df.columns or '–†–∞–π–æ–Ω' not in df.columns or '–ü–ª–æ—â–∞–¥—å' not in df.columns:
        return None, None, None

    # –û—á–∏—Å—Ç–∫–∞ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    df = df.copy()
    df['–¶–µ–Ω–∞'] = pd.to_numeric(df['–¶–µ–Ω–∞'].astype(str).str.replace(',', '').str.replace(' ', ''), errors='coerce')
    df['–ü–ª–æ—â–∞–¥—å'] = pd.to_numeric(df['–ü–ª–æ—â–∞–¥—å'].astype(str).str.replace(',', '').str.replace(' ', ''), errors='coerce')
    
    # –†–∞—Å—á–µ—Ç —Ü–µ–Ω—ã –∑–∞ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–π –º–µ—Ç—Ä
    df['–¶–µ–Ω–∞_–∑–∞_–º2'] = df['–¶–µ–Ω–∞'] / df['–ü–ª–æ—â–∞–¥—å']
    
    # –†–∞—Å—á–µ—Ç —Å—Ä–µ–¥–Ω–µ–π —Ü–µ–Ω—ã –ø–æ —Ä–∞–π–æ–Ω–∞–º
    avg_price_by_district = df.groupby('–†–∞–π–æ–Ω')['–¶–µ–Ω–∞_–∑–∞_–º2'].mean()
    
    # –ü–æ–∏—Å–∫ –æ–±—ä–µ–∫—Ç–æ–≤ —Å —Ü–µ–Ω–æ–π –Ω–∏–∂–µ 80% –æ—Ç —Å—Ä–µ–¥–Ω–µ–π –ø–æ —Ä–∞–π–æ–Ω—É
    df['–°—Ä–µ–¥–Ω—è—è_—Ü–µ–Ω–∞_—Ä–∞–π–æ–Ω–∞'] = df['–†–∞–π–æ–Ω'].map(avg_price_by_district)
    df['–ü—Ä–æ—Ü–µ–Ω—Ç_–æ—Ç_—Å—Ä–µ–¥–Ω–µ–π'] = (df['–¶–µ–Ω–∞_–∑–∞_–º2'] / df['–°—Ä–µ–¥–Ω—è—è_—Ü–µ–Ω–∞_—Ä–∞–π–æ–Ω–∞']) * 100
    good_deals = df[df['–ü—Ä–æ—Ü–µ–Ω—Ç_–æ—Ç_—Å—Ä–µ–¥–Ω–µ–π'] < 80].copy()
    
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤—ã–≥–æ–¥–Ω–æ—Å—Ç–∏ (–ø—Ä–æ—Ü–µ–Ω—Ç –æ—Ç —Å—Ä–µ–¥–Ω–µ–π —Ü–µ–Ω—ã)
    good_deals = good_deals.sort_values('–ü—Ä–æ—Ü–µ–Ω—Ç_–æ—Ç_—Å—Ä–µ–¥–Ω–µ–π')
    
    return df, good_deals, avg_price_by_district

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–ò–º–ø–æ—Ä—Ç –∏ –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏",
    page_icon="üè†",
    layout="wide"
)

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å –ª–æ–≥–æ—Ç–∏–ø–æ–º
col1, col2 = st.columns([1, 4])
with col1:
    st.image("https://kvaris.com/wp-content/uploads/2.svg", width=100)
with col2:
    st.title("–ò–º–ø–æ—Ä—Ç –∏ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏")

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤
uploaded_files = st.file_uploader(
    "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã Excel –∏–ª–∏ CSV —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏",
    type=["xlsx", "xls", "csv"],
    accept_multiple_files=True
)

if uploaded_files:
    all_data = []
    
    for file in uploaded_files:
        st.subheader(f"üìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {file.name}")
        
        try:
            # –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
            if file.name.endswith('.csv'):
                df = pd.read_csv(file, header=None)
            else:
                excel_file = pd.ExcelFile(file)
                sheets = excel_file.sheet_names
                
                if len(sheets) > 1:
                    selected_sheet = st.selectbox(
                        "–í—ã–±–µ—Ä–∏—Ç–µ –ª–∏—Å—Ç Excel:",
                        sheets,
                        key=f"sheet_select_{file.name}"
                    )
                    df = pd.read_excel(file, sheet_name=selected_sheet, header=None)
                else:
                    df = pd.read_excel(file, header=None)

            # –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–≤—ã—Ö —Å—Ç—Ä–æ–∫ —Ñ–∞–π–ª–∞
            preview_rows, suggested_header = detect_header_row(df)
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–µ–≤—å—é –¥–∞–Ω–Ω—ã—Ö
            st.write("üëÄ –ü—Ä–µ–≤—å—é –ø–µ—Ä–≤—ã—Ö —Å—Ç—Ä–æ–∫ —Ñ–∞–π–ª–∞:")
            for row in preview_rows:
                st.write(
                    f"–°—Ç—Ä–æ–∫–∞ {row['row_num'] + 1}: {row['content']}\n"
                    f"–ù–µ–ø—É—Å—Ç—ã—Ö —è—á–µ–µ–∫: {row['non_empty']}, "
                    f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∞: {row['header_likelihood']}"
                )

            # –í—ã–±–æ—Ä —Å—Ç—Ä–æ–∫–∏ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ —Å –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º
            header_row = st.number_input(
                "–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏ —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏:",
                min_value=1,
                max_value=len(df),
                value=suggested_header + 1,
                key=f"header_select_{file.name}"
            ) - 1

            # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤—ã–±—Ä–∞–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–æ–∫
            df.columns = df.iloc[header_row]
            df = df.iloc[header_row + 1:].copy()
            
            # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            df = df.dropna(axis=1, how='all')
            df = df.loc[:, ~df.columns.str.contains('^Unnamed:', na=False)]
            
            # –ü–æ–∫–∞–∑–∞—Ç—å –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            valid_columns = [str(col) for col in df.columns if not pd.isna(col) and str(col).strip() != ""]
            st.write("üîé –ù–∞–π–¥–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏:", valid_columns)
            
            # –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
            column_map = {}
            for std_col, possible_names in STANDARD_COLUMNS.items():
                # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ–¥—Ö–æ–¥—è—â–µ–π –∫–æ–ª–æ–Ω–∫–∏
                found_col = None
                for name in possible_names:
                    matching_cols = [col for col in valid_columns if name.lower() in str(col).lower()]
                    if matching_cols:
                        found_col = matching_cols[0]
                        break
                
                # –í—ã–±–æ—Ä –∫–æ–ª–æ–Ω–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
                column_map[std_col] = st.selectbox(
                    f"–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫—É –¥–ª—è '{std_col}'",
                    options=[""] + valid_columns,
                    index=valid_columns.index(found_col) + 1 if found_col else 0,
                    key=f"{file.name}_{std_col}"
                )
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ DataFrame —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
            mapped_df = pd.DataFrame()
            for std_col, selected_col in column_map.items():
                if selected_col:
                    mapped_df[std_col] = df[selected_col]
            
            if not mapped_df.empty:
                all_data.append(mapped_df)
                st.success(f"‚úÖ –§–∞–π–ª {file.name} –æ–±—Ä–∞–±–æ—Ç–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            else:
                st.warning("‚ö†Ô∏è –ù–µ –≤—ã–±—Ä–∞–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞")
            
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file.name}: {str(e)}")
            continue
    
    if all_data:
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö
        final_df = pd.concat(all_data, ignore_index=True)
        
        # –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö
        df_analyzed, good_deals, avg_prices = analyze_prices(final_df)
        
        if df_analyzed is not None:
            # –í–∫–ª–∞–¥–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –≤–∏–¥–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
            tab1, tab2, tab3 = st.tabs(["üìä –í—Å–µ –¥–∞–Ω–Ω—ã–µ", "üí∞ –í—ã–≥–æ–¥–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è", "üìà –ê–Ω–∞–ª–∏–∑ —Ü–µ–Ω"])
            
            with tab1:
                st.subheader("–í—Å–µ –æ–±—ä–µ–∫—Ç—ã")
                st.dataframe(final_df)
            
            with tab2:
                st.subheader("üéØ –í—ã–≥–æ–¥–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (–Ω–∏–∂–µ 80% —Å—Ä–µ–¥–Ω–µ–π —Ü–µ–Ω—ã —Ä–∞–π–æ–Ω–∞)")
                if not good_deals.empty:
                    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    display_deals = good_deals.copy()
                    display_deals['–¶–µ–Ω–∞_–∑–∞_–º2'] = display_deals['–¶–µ–Ω–∞_–∑–∞_–º2'].round(0).astype(int)
                    display_deals['–ü—Ä–æ—Ü–µ–Ω—Ç_–æ—Ç_—Å—Ä–µ–¥–Ω–µ–π'] = display_deals['–ü—Ä–æ—Ü–µ–Ω—Ç_–æ—Ç_—Å—Ä–µ–¥–Ω–µ–π'].round(1)
                    display_deals['–≠–∫–æ–Ω–æ–º–∏—è'] = (100 - display_deals['–ü—Ä–æ—Ü–µ–Ω—Ç_–æ—Ç_—Å—Ä–µ–¥–Ω–µ–π']).round(1)
                    
                    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    for _, row in display_deals.iterrows():
                        with st.container():
                            col1, col2 = st.columns([2, 1])
                            with col1:
                                st.markdown(f"""
                                    **{row['–ö–æ–º–ø–ª–µ–∫—Å']}** –≤ —Ä–∞–π–æ–Ω–µ {row['–†–∞–π–æ–Ω']}
                                    - üí∞ –¶–µ–Ω–∞: ‡∏ø{int(row['–¶–µ–Ω–∞']):,}
                                    - üìè –ü–ª–æ—â–∞–¥—å: {int(row['–ü–ª–æ—â–∞–¥—å'])} –º¬≤
                                    - üè∑Ô∏è –¶–µ–Ω–∞ –∑–∞ –º¬≤: ‡∏ø{int(row['–¶–µ–Ω–∞_–∑–∞_–º2']):,}
                                    """)
                            with col2:
                                st.markdown(f"""
                                    **–í—ã–≥–æ–¥–∞: {row['–≠–∫–æ–Ω–æ–º–∏—è']}%**
                                    - üéØ {row['–ü—Ä–æ—Ü–µ–Ω—Ç_–æ—Ç_—Å—Ä–µ–¥–Ω–µ–π']}% –æ—Ç —Å—Ä–µ–¥–Ω–µ–π
                                    - üõèÔ∏è –°–ø–∞–ª–µ–Ω: {row['–°–ø–∞–ª–µ–Ω']}
                                    - üèóÔ∏è –≠—Ç–∞–∂–µ–π: {row['–≠—Ç–∞–∂–µ–π']}
                                    """)
                            st.divider()
                else:
                    st.info("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –Ω–∏–∂–µ 80% –æ—Ç —Å—Ä–µ–¥–Ω–µ–π —Ü–µ–Ω—ã —Ä–∞–π–æ–Ω–∞")
            
            with tab3:
                st.subheader("–ê–Ω–∞–ª–∏–∑ —Ü–µ–Ω –ø–æ —Ä–∞–π–æ–Ω–∞–º")
                
                # –ì—Ä–∞—Ñ–∏–∫ —Å—Ä–µ–¥–Ω–∏—Ö —Ü–µ–Ω –ø–æ —Ä–∞–π–æ–Ω–∞–º
                fig, ax = plt.subplots(figsize=(10, 6))
                avg_prices.sort_values().plot(kind='barh', ax=ax)
                plt.title("–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ –∑–∞ –º¬≤ –ø–æ —Ä–∞–π–æ–Ω–∞–º")
                plt.xlabel("–¶–µ–Ω–∞ –∑–∞ –º¬≤ (‡∏ø)")
                st.pyplot(fig)
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä–∞–π–æ–Ω–∞–º
                st.subheader("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä–∞–π–æ–Ω–∞–º")
                stats_df = df_analyzed.groupby('–†–∞–π–æ–Ω').agg({
                    '–¶–µ–Ω–∞_–∑–∞_–º2': ['mean', 'min', 'max', 'count']
                }).round(0)
                stats_df.columns = ['–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞/–º¬≤', '–ú–∏–Ω —Ü–µ–Ω–∞/–º¬≤', '–ú–∞–∫—Å —Ü–µ–Ω–∞/–º¬≤', '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤']
                st.dataframe(stats_df)
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∞–π–ª–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            final_df.to_excel(writer, sheet_name='–í—Å–µ –æ–±—ä–µ–∫—Ç—ã', index=False)
            if df_analyzed is not None and not good_deals.empty:
                good_deals.to_excel(writer, sheet_name='–í—ã–≥–æ–¥–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è', index=False)
        output.seek(0)
        
        # –ö–Ω–æ–ø–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        st.download_button(
            label="üíæ –°–∫–∞—á–∞—Ç—å –¥–∞–Ω–Ω—ã–µ (–≤–∫–ª—é—á–∞—è –∞–Ω–∞–ª–∏–∑)",
            data=output,
            file_name="real_estate_analysis.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        ) 